# Example of a paper entry
@misc{qian2023communicative,
      title={Communicative Agents for Software Development}, 
      author={Chen Qian and Xin Cong and Wei Liu and Cheng Yang and Weize Chen and Yusheng Su and Yufan Dang and Jiahao Li and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2023},
      url={https://arxiv.org/abs/2307.07924},
      environments = {collaboration, embodied},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {rule_based},
      other = {n/a},
      eprint={2307.07924},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}
## Papers
### Surveys and Overview

### Environments
@misc{zhao2023competeai,
      title={CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents}, 
      author={Qinlin Zhao and Jindong Wang and Yixuan Zhang and Yiqiao Jin and Kaijie Zhu and Hao Chen and Xing Xie},
      environments = {competition, text},
      agents = {prompting_and_in_context_learning, two_agents},
      evaluation = {rule_based},
      url = {https://arxiv.org/abs/2310.17512},
      other = {n/a},
      year={2023},
      eprint={2310.17512},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

#### Text and Speech Environments

#### Embodied Environments

#### Virtual Environments

#### Robotics
@InProceedings{pmlr-v205-xiong23a,
    title = {RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments},
    author = {Xiong, Haoyu and Fu, Haoyuan and Zhang, Jieyi and Bao, Chen and Zhang, Qiang and Huang, Yongxi and Xu, Wenqiang and Garg, Animesh and Lu, Cewu},
    booktitle = {Proceedings of The 6th Conference on Robot Learning},
    pages = {1--10},
    year = {2023},
    editor = {Liu, Karen and Kulic, Dana and Ichnowski, Jeff},
    volume = {205},
    series = {Proceedings of Machine Learning Research},
    month = {12},
    publisher =  {PMLR},
    pdf = {https://proceedings.mlr.press/v205/xiong23a/xiong23a.pdf},
    url = {https://proceedings.mlr.press/v205/xiong23a.html},
    environments = {implicit_objectives, robotics},
    agents = {reinforcement_learning, agents_with_memory},
    evaluation = {human, rule_based},
    other = {simulated_humans}
}


@inproceedings{saycan2022arxiv,
    title={Do As I Can and Not As I Say: Grounding Language in Robotic Affordances},
    author={Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng},
    booktitle={arXiv preprint arXiv:2204.01691},
    year={2022},
    month={8},
    url = {https://say-can.github.io/},
    environments = {mixed_objectives, implicit_objectives, robotics},
    agents = {finetuning, reinforcement_learning, agents_with_memory},
    evaluation = {human, rule_based, model_based},
    other = {simulated_humans}
}

@inproceedings{huang2022inner,
    title={Inner Monologue: Embodied Reasoning through Planning with Language Models},
    author={Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and Pierre Sermanet and Noah Brown and Tomas Jackson and Linda Luu and Sergey Levine and Karol Hausman and Brian Ichter},
    booktitle={arXiv preprint arXiv:2207.05608},
    year={2022},
    month={6},
    url = {https://arxiv.org/abs/2207.05608},
    environments = {mixed_objectives, implicit_objectives, robotics},
    agents = {finetuning, reinforcement_learning, agents_with_memory},
    evaluation = {human, rule_based, model_based},
    other = {simulated_humans}
}

@inproceedings{Wang2023One,
    title={One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments},
    author={Wang, Yufei and Sun, Zhanyi and Erickson, Zackory and Held, David},
    booktitle={Robotics: Science and Systems (RSS)},
    year={2023},
    month={6},
    url = {https://arxiv.org/abs/2306.12372},
    environments = {robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}     

@misc{wang2023cogail,
    title={Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration}, 
    author={Chen Wang and Claudia Pérez-D'Arpino and Danfei Xu and Li Fei-Fei and C. Karen Liu and Silvio Savarese},
    year={2023},
    month={9},
    url = {https://arxiv.org/abs/2108.06038},
    eprint={2108.06038},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, reinforcement_learning},
    evaluation = {human},
    other = {human_agent, simulated_humans}
}

@misc{shi2024yell,
    title={Yell At Your Robot: Improving On-the-Fly from Language Corrections}, 
    author={Lucy Xiaoyang Shi and Zheyuan Hu and Tony Z. Zhao and Archit Sharma and Karl Pertsch and Jianlan Luo and Sergey Levine and Chelsea Finn},
    year={2024},
    month={3},
    url={https://arxiv.org/abs/2403.12910},
    eprint={2403.12910},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, finetuning, reinforcement_learning, agents_with_memory},
    evaluation = {human},
    other = {human_agent}
}

@article{sheridan2016human,
    title={Human--robot interaction: status and challenges},
    author={Sheridan, Thomas B},
    journal={Human factors},
    month={4},
    url={https://journals.sagepub.com/doi/10.1177/0018720816644364},
    volume={58},
    number={4},
    pages={525--532},
    year={2016},
    publisher={SAGE Publications Sage CA: Los Angeles, CA},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, finetuning, reinforcement_learning},
    evaluation = {human},
    other = {human_agent}
}


@article{onnasch2021taxonomy,
    title={A taxonomy to structure and analyze human--robot interaction},
    author={Onnasch, Linda and Roesler, Eileen},
    journal={International Journal of Social Robotics},
    volume={13},
    number={4},
    pages={833--849},
    year={2021},
    publisher={Springer},
    month={6},
    url={https://link.springer.com/article/10.1007/s12369-020-00666-5},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents},
    evaluation = {human},
    other = {human_agent}
}

@article{robinson2023robotic,
    title={Robotic vision for human-robot interaction and collaboration: A survey and systematic review},
    author={Robinson, Nicole and Tidd, Brendan and Campbell, Dylan and Kuli{\'c}, Dana and Corke, Peter},
    journal={ACM Transactions on Human-Robot Interaction},
    volume={12},
    number={1},
    pages={1--66},
    year={2023},
    month={7},
    url={https://arxiv.org/abs/2307.15363},
    publisher={ACM New York, NY},
    environments = {collaboration, mixed_objectives, implicit_objectives, robotics},
    agents = {two_agents, agent_teams, agents_with_personas},
    evaluation = {human, rule_based},
    other = {human_agent, simulated_humans}
}

@article{dahiya2023survey,
    title={A survey of multi-agent Human--Robot Interaction systems},
    author={Dahiya, Abhinav and Aroyo, Alexander M and Dautenhahn, Kerstin and Smith, Stephen L},
    journal={Robotics and Autonomous Systems},
    volume={161},
    pages={104335},
    year={2022},
    month={10},
    url={https://arxiv.org/abs/2212.05286},
    publisher={Elsevier},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {two_agents, more_than_three_agents, agent_teams},
    evaluation = {human},
    other = {human_agent}
}

@article{10.1145/3570169,
    author = {Urakami, Jacqueline and Seaborn, Katie},
    title = {Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective},
    year = {2023},
    issue_date = {June 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {12},
    number = {2},
    url = {https://doi.org/10.1145/3570169},
    doi = {10.1145/3570169},
    abstract = {Communication between people is characterized by a broad range of nonverbal cues. Transferring these cues into the design of robots and other artificial agents that interact with people may foster more natural, inviting, and accessible experiences. In this article, we offer a series of definitive nonverbal codes for human–robot interaction (HRI) that address the five human sensory systems (visual, auditory, haptic, olfactory, and gustatory) drawn from the field of communication studies. We discuss how these codes can be translated into design patterns for HRI using a curated sample of the communication studies and HRI literatures. As nonverbal codes are an essential mode in human communication, we argue that integrating robotic nonverbal codes in HRI will afford robots a feeling of “aliveness” or “social agency” that would otherwise be missing. We end with suggestions for research directions to stimulate work on nonverbal communication within the field of HRI and improve communication between people and robots.},
    journal = {J. Hum.-Robot Interact.},
    month = {3},
    articleno = {22},
    numpages = {21},
    keywords = {nonverbal codes, communication studies, human robot interaction, nonverbal communication, Robotics},
    environments = {collaboration, mixed_objectives, implicit_objectives, robotics},
    agents = {two_agents},
    evaluation = {human},
    other = {human_agent}
}

@article{10.1145/3571718,
    author = {Winkle, Katie and Lagerstedt, Erik and Torre, Ilaria and Offenwanger, Anna},
    title = {15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction},
    year = {2023},
    issue_date = {September 2023},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {12},
    number = {3},
    url = {https://doi.org/10.1145/3571718},
    doi = {10.1145/3571718},
    abstract = {Recent work identified a concerning trend of disproportional gender representation in research participants in Human–Computer Interaction (HCI). Motivated by the fact that Human–Robot Interaction (HRI) shares many participant practices with HCI, we explored whether this trend is mirrored in our field. By producing a dataset covering participant gender representation in all 684 full papers published at the HRI conference from 2006–2021, we identify current trends in HRI research participation. We find an over-representation of men in research participants to date, as well as inconsistent and/or incomplete gender reporting, which typically engages in a binary treatment of gender at odds with published best practice guidelines. We further examine if and how participant gender has been considered in user studies to date, in-line with current discourse surrounding the importance and/or potential risks of gender based analyses. Finally, we complement this with a survey of HRI researchers to examine correlations between who is doing with the who is taking part, to further reflect on factors which seemingly influence gender bias in research participation across different sub-fields of HRI. Through our analysis, we identify areas for improvement, but also reason for optimism, and derive some practical suggestions for HRI researchers going forward.},
    journal = {J. Hum.-Robot Interact.},
    month = {4},
    articleno = {28},
    numpages = {28},
    keywords = {Gender, systematic review, user study methodologies, participant recruitment, inclusivity},
    environments = {robotics},
    agents = {two_agents},
    evaluation = {human},
    other = {human_agent}
}

### Modeling

#### In-context Learning
@misc{wang2023voyager,
    title={Voyager: An Open-Ended Embodied Agent with Large Language Models}, 
    author={Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
    year={2023},
    month={5},
    url={https://arxiv.org/abs/2305.16291},
    eprint={2305.16291},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    environments = {mixed_objectives, implicit_objectives, embodied},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{kim2023language,
    title={Language Models can Solve Computer Tasks}, 
    author={Geunwoo Kim and Pierre Baldi and Stephen McAleer},
    year={2023},
    month={11},
    url={https://arxiv.org/abs/2303.17491},
    eprint={2303.17491},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{ma2024laser,
    title={LASER: LLM Agent with State-Space Exploration for Web Navigation}, 
    author={Kaixin Ma and Hongming Zhang and Hongwei Wang and Xiaoman Pan and Wenhao Yu and Dong Yu},
    year={2024},
    month={2},
    url={https://arxiv.org/abs/2309.08172},
    eprint={2309.08172},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{sridhar2023hierarchical,
    title={Hierarchical Prompting Assists Large Language Model on Web Navigation}, 
    author={Abishek Sridhar and Robert Lo and Frank F. Xu and Hao Zhu and Shuyan Zhou},
    year={2023},
    month={10},
    url={https://arxiv.org/abs/2305.14257},
    eprint={2305.14257},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{zheng2024synapse,
    title={Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control},
    author={Longtao Zheng and Rundong Wang and Xinrun Wang and Bo An},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    month={1},
    url={https://openreview.net/forum?id=Pc8AU1aF5e},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{sun2023adaplanner,
    title={AdaPlanner: Adaptive Planning from Feedback with Language Models},
    author={Haotian Sun and Yuchen Zhuang and Lingkai Kong and Bo Dai and Chao Zhang},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    month={11},
    url={https://openreview.net/forum?id=rnKgbKmelt},
    environments = {mixed_objectives, implicit_objectives, text},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{wu2023spring,
    title={SPRING: Studying the Paper and Reasoning to Play Games}, 
    author={Yue Wu and Shrimai Prabhumoye and So Yeon Min and Yonatan Bisk and Ruslan Salakhutdinov and Amos Azaria and Tom Mitchell and Yuanzhi Li},
    year={2023},
    month={5},
    url={https://arxiv.org/abs/2305.15486},
    eprint={2305.15486},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    environments = {mixed_objectives, implicit_objectives, text},
    agents = {prompting_and_in_context_learning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{nair2023dera,
    title={DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents}, 
    author={Varun Nair and Elliot Schumacher and Geoffrey Tso and Anitha Kannan},
    year={2023},
    month={3},
    url={https://arxiv.org/abs/2303.17071},
    eprint={2303.17071},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {collaboration, mixed_objectives, implicit_objectives, text},
    agents = {prompting_and_in_context_learning, agent_teams, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}
#### Finetuning
@misc{gur2023understanding,
    title={Understanding HTML with Large Language Models}, 
    author={Izzeddin Gur and Ofir Nachum and Yingjie Miao and Mustafa Safdari and Austin Huang and Aakanksha Chowdhery and Sharan Narang and Noah Fiedel and Aleksandra Faust},
    year={2023},
    month={5},
    url={https://arxiv.org/abs/2210.03945},
    eprint={2210.03945},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{
    furuta2023instructionfinetuned,
    title={Instruction-Finetuned Foundation Models for Multimodal Web Navigation},
    author={Hiroki Furuta and Ofir Nachum and Kuang-Huei Lee and Yutaka Matsuo and Shixiang Shane Gu and Izzeddin Gur},
    booktitle={ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models},
    year={2023},
    month={5},
    url={https://openreview.net/forum?id=oLc9sGOBbc},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{yao2023react,
    title={ReAct: Synergizing Reasoning and Acting in Language Models}, 
    author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
    year={2023},
    month={10},
    eprint={2210.03629},
    url={https://arxiv.org/abs/2210.03629},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{gur2024a,
    title={A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis},
    author={Izzeddin Gur and Hiroki Furuta and Austin V Huang and Mustafa Safdari and Yutaka Matsuo and Douglas Eck and Aleksandra Faust},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    month={1},
    url={https://openreview.net/forum?id=9JQtrumvg8},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@inproceedings{shaw2023from,
    title={From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces},
    author={Peter Shaw and Mandar Joshi and James Cohan and Jonathan Berant and Panupong Pasupat and Hexiang Hu and Urvashi Khandelwal and Kenton Lee and Kristina Toutanova},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    month={11},
    url={https://openreview.net/forum?id=3PjCt4kmRx},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{zheng2024gpt4vision,
    title={GPT-4V(ision) is a Generalist Web Agent, if Grounded}, 
    author={Boyuan Zheng and Boyu Gou and Jihyung Kil and Huan Sun and Yu Su},
    year={2024},
    month={1},
    url={https://arxiv.org/abs/2401.01614},
    eprint={2401.01614},
    archivePrefix={arXiv},
    primaryClass={cs.IR},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

@misc{kil2024dualview,
    title={Dual-View Visual Contextualization for Web Navigation}, 
    author={Jihyung Kil and Chan Hee Song and Boyuan Zheng and Xiang Deng and Yu Su and Wei-Lun Chao},
    year={2024},
    month={2},
    url={https://arxiv.org/abs/2402.04476},
    eprint={2402.04476},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    environments = {mixed_objectives, implicit_objectives, virtual},
    agents = {prompting_and_in_context_learning, finetuning, agents_with_memory},
    evaluation = {rule_based},
    other = {simulated_humans}
}

#### Reinforcement learning

### Evaluating social agents

#### Evaluating text social agents
@inproceedings{zhou2024sotopia,
title={SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents},
author={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},
booktitle={ICLR},
environments = {mixed_objectives, text},
agents = {prompting_and_in_context_learning, two_agents},
evaluation = {model_based, human},
other = {human_agent},
year={2024},
month = {10},
url={https://openreview.net/forum?id=mM7VurbA4r}
}


#### Evaluating embodied social agents
@misc{guo2024embodied,
      title={Embodied LLM Agents Learn to Cooperate in Organized Teams}, 
      author={Xudong Guo and Kaixuan Huang and Jiale Liu and Wenhui Fan and Natalia Vélez and Qingyun Wu and Huazheng Wang and Thomas L. Griffiths and Mengdi Wang},
      year={2024},
      environments = {collaboration, embodied},
      agents = {prompting_and_in_context_learning, more_than_three_agents},
      evaluation = {model_based, human},
      url={https://arxiv.org/abs/2403.12482},
      other = {education},
      eprint={2403.12482},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

#### Evaluating virtual social agents

#### Evaluating robotics in social contexts

@misc{sferrazza2024humanoidbench,
    title={HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation}, 
    author={Carmelo Sferrazza and Dun-Ming Huang and Xingyu Lin and Youngwoon Lee and Pieter Abbeel},
    year={2024},
    month={3},
    url={https://arxiv.org/abs/2403.10506},
    eprint={2403.10506},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, model_based},
    other = {human_agent, simulated_humans}
}

@INPROCEEDINGS{1174284,
    author={Scholtz, J.},
    booktitle={36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the}, 
    title={Theory and evaluation of human robot interactions}, 
    year={2003},
    month={1},
    url={https://ieeexplore.ieee.org/document/1174284},
    volume={},
    number={},
    pages={10 pp.-},
    keywords={Human robot interaction;Robot sensing systems;Mobile robots;Software architecture;NIST;Feeds;User interfaces;Computer architecture;Human computer interaction;Man machine systems},
    doi={10.1109/HICSS.2003.1174284},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human},
    other = {human_agent}
  
}
  
@inproceedings{10.1145/1121241.1121249,
    author = {Steinfeld, Aaron and Fong, Terrence and Kaber, David and Lewis, Michael and Scholtz, Jean and Schultz, Alan and Goodrich, Michael},
    title = {Common metrics for human-robot interaction},
    year = {2006},
    month = {3},
    isbn = {1595932941},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1121241.1121249},
    doi = {10.1145/1121241.1121249},
    abstract = {This paper describes an effort to identify common metrics for task-oriented human-robot interaction (HRI). We begin by discussing the need for a toolkit of HRI metrics. We then describe the framework of our work and identify important biasing factors that must be taken into consideration. Finally, we present suggested common metrics for standardization and a case study. Preparation of a larger, more detailed toolkit is in progress.},
    booktitle = {Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction},
    pages = {33–40},
    numpages = {8},
    keywords = {unmanned ground vehicles, metrics, human-robot interaction},
    location = {Salt Lake City, Utah, USA},
    series = {HRI '06},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based, model_based},
    other = {human_agent}
}

@article{zacharaki2020safety,
    title={Safety bounds in human robot interaction: A survey},
    author={Zacharaki, Angeliki and Kostavelis, Ioannis and Gasteratos, Antonios and Dokas, Ioannis},
    journal={Safety science},
    volume={127},
    pages={104667},
    year={2020},
    month = {7},
    publisher={Elsevier},
    url = {https://www.sciencedirect.com/science/article/pii/S0925753520300643},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{hancock2011meta,
    title={A meta-analysis of factors affecting trust in human-robot interaction},
    author={Hancock, Peter A and Billings, Deborah R and Schaefer, Kristin E and Chen, Jessie YC and De Visser, Ewart J and Parasuraman, Raja},
    journal={Human factors},
    volume={53},
    number={5},
    pages={517--527},
    year={2011},
    month={10},
    url={https://journals.sagepub.com/doi/10.1177/0018720811417254},
    publisher={Sage Publications Sage CA: Los Angeles, CA},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{bartneck2009measurement,
    title={Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots},
    author={Bartneck, Christoph and Kuli{\'c}, Dana and Croft, Elizabeth and Zoghbi, Susana},
    journal={International journal of social robotics},
    volume={1},
    pages={71--81},
    year={2009},
    month={11},
    publisher={Springer},
    url={https://link.springer.com/article/10.1007/s12369-008-0001-3},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{iocchi2015robocup,
    title={RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots},
    author={Iocchi, Luca and Holz, Dirk and Ruiz-del-Solar, Javier and Sugiura, Komei and Van Der Zant, Tijn},
    journal={Artificial Intelligence},
    volume={229},
    pages={258--281},
    year={2015},
    month={12},
    url={https://www.sciencedirect.com/science/article/pii/S0004370215001174},
    publisher={Elsevier},
    environments = {collaboration, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}

@article{doi:10.1080/01691864.2019.1698462,
    author = {Y. Mizuchi and T. Inamura},
    title = {Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition},
    journal = {Advanced Robotics},
    volume = {34},
    number = {3-4},
    pages = {142--156},
    year = {2020},
    month = {12},
    publisher = {Taylor \& Francis},
    doi = {10.1080/01691864.2019.1698462},
    url = {https://doi.org/10.1080/01691864.2019.1698462},
    environments = {competition, mixed_objectives, robotics},
    agents = {reinforcement_learning},
    evaluation = {human, rule_based},
    other = {human_agent}
}
### Interactions with humans

#### Human-Chatbot Interaction

#### Human-Embodied Agent Interaction

#### Human Robot Interaction

#### Human-Human Interaction

### Challenges

#### Theory of Mind

#### Social Learning

#### Simultaneous Interaction

### Applications

#### Health

#### Policy

#### Education

### Concerns

#### Risks

#### Safety





