{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"\ud83d\udde3\ufe0f\ud83d\udc65 Awesome Social Agents <p>For the best experience, we recommend reading this document on the website.</p> <p>The rise of Large Language Models (LLMs)/foundational models presents new opportunities for simulating complex human social behaviors. As a result, there is a rapidly growing body of work emerging in this domain. We hope to categorize and synergize recent efforts to provide a comprehensive guidebook of social agents weaving together multiple domains, including language, embodiment, and robotics. </p> <p>Our goal is to offer insights crucial for understanding and harnessing social agents' potential impact on society. We strive to keep these updated regularly and continuously. We greatly appreciate any contributions via PRs, issues, emails, or other methods.</p> <p>Note</p> <ul> <li>Agent and Environment (Sutton and Barto 2018): An agent is a goal-driven decision-maker that sense and act upon the state of the environment. An environment comprises the state outside the agent, including the other agents if any. </li> <li>Social Agent: An agent that interacts with a multi-agent environment.</li> <li>Socially Intelligent Agent: A social agent that interacts and communicates with other agents in a human-interpretable way. more notes<ol> <li>The social intelligence that we are focusing on is human-like, excluding the collective intelligence in a lot of social animals like ants, bees, fishes. </li> <li>To understand whether an entity is a (social) agent, we have to situate it in an environment. It is not possible to discuss an agent outside of an environment. </li> <li>We acknowledge there are many types of definitions for social agents. Our defitions here help narrow down the scope of our survey.</li> <p>\ud83d\uddc2\ufe0f Check out the examples of social agents. \ud83d\udcda Check out the table format of the collected papers here.</p> <p>\ud83d\udcdd We are currently working on a survey paper related to content of this repository. Stay tuned for updates!</p>"},{"location":"#installation","title":"Installation","text":"<p>This repo supports Python 3.9 and above. In one line, to use a virtual environment, e.g. with anaconda3: </p> <p><code>conda create -n awsome-social-agents python=3.9; conda activate awsome-social-agents; python -m install requirements.txt</code></p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ul> <li>Papers</li> <li>Surveys and Overview</li> <li>Environments<ul> <li>Text and Speech Environments</li> <li>Embodied Environments</li> <li>Virtual Environments</li> <li>Robotics</li> </ul> </li> <li>Modeling<ul> <li>In-context Learning</li> <li>Finetuning</li> <li>Reinforcement learning</li> </ul> </li> <li>Evaluating social agents<ul> <li>Evaluating text social agents</li> <li>Evaluating embodied social agents</li> <li>Evaluating virtual social agents</li> <li>Evaluating robotics in social contexts</li> </ul> </li> <li>Interactions with humans<ul> <li>Human-Chatbot Interaction</li> <li>Human-Embodied Agent Interaction</li> <li>Human Robot Interaction</li> <li>Human-Human Interaction</li> </ul> </li> <li>Challenges<ul> <li>Theory of Mind</li> <li>Social Learning</li> <li>Simultaneous Interaction</li> </ul> </li> <li>Applications<ul> <li>Health</li> <li>Policy</li> <li>Education</li> </ul> </li> <li>Concerns<ul> <li>Risks</li> <li>Safety</li> </ul> </li> </ul>"},{"location":"#papers","title":"Papers","text":""},{"location":"#surveys-and-overview","title":"Surveys and Overview","text":"<p>[June, 2023] Socially intelligent machines that learn from humans and help humans learn, Gweon et al., arXiv</p>"},{"location":"#environments","title":"Environments","text":""},{"location":"#text-and-speech-environments","title":"Text and Speech Environments","text":"<p>[October, 2023] SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents, Xuhui Zhou et al., ICLR</p> <p>[October, 2023] CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents, Qinlin Zhao et al., arXiv</p>"},{"location":"#embodied-environments","title":"Embodied Environments","text":""},{"location":"#virtual-environments","title":"Virtual Environments","text":""},{"location":"#robotics","title":"Robotics","text":"<p>[December, 2023] RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments, Haoyu Xiong et al., Proceedings of The 6th Conference on Robot Learning </p> <p>[August, 2022] Do As I Can and Not As I Say: Grounding Language in Robotic Affordances, Michael Ahn et al., arXiv preprint arXiv:2204.01691         </p> <p>[June, 2022] Inner Monologue: Embodied Reasoning through Planning with Language Models, Wenlong Huang et al., arXiv preprint arXiv:2207.05608                    </p> <p>[June, 2023] One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments, Yufei Wang et al., Robotics: Science and Systems (RSS)        </p> <p>[August, 2023] Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration, Chen Wang et al., arXiv                                                 </p> <p>[March, 2024] Yell At Your Robot: Improving On-the-Fly from Language Corrections, Lucy Xiaoyang Shi et al., arXiv                                   </p> <p>[April, 2016] Human--robot interaction: status and challenges, Thomas B Sheridan et al., Human factors             </p> <p>[June, 2021] A taxonomy to structure and analyze human--robot interaction, Linda Onnasch et al., International Journal of Social Robotics         </p> <p>[July, 2023] Robotic vision for human-robot interaction and collaboration: A survey and systematic review, Nicole Robinson et al., ACM Transactions on Human-Robot Interaction         </p> <p>[October, 2022] A survey of multi-agent Human--Robot Interaction systems, Abhinav Dahiya et al., Robotics and Autonomous Systems                                             </p> <p>[March, 2023] Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective, Jacqueline Urakami et al., J. Hum.-Robot Interact.               </p> <p>[April, 2023] 15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction, Katie Winkle et al., J. Hum.-Robot Interact.                           </p>"},{"location":"#modeling","title":"Modeling","text":""},{"location":"#in-context-learning","title":"In-context Learning","text":"<p>[May, 2023] Voyager: An Open-Ended Embodied Agent with Large Language Models, Guanzhi Wang et al., arXiv</p> <p>[March, 2023] Language Models can Solve Computer Tasks, Geunwoo Kim et al., arXiv                                                                                                                                                               </p> <p>[September, 2024] LASER: LLM Agent with State-Space Exploration for Web Navigation, Kaixin Ma et al., arXiv                                                                                                                                      </p> <p>[May, 2023] Hierarchical Prompting Assists Large Language Model on Web Navigation, Abishek Sridhar et al., arXiv                                                                                                                                </p> <p>[January, 2024] Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control, Longtao Zheng et al., The Twelfth International Conference on Learning Representations                                                    </p> <p>[November, 2023] AdaPlanner: Adaptive Planning from Feedback with Language Models, Haotian Sun et al., Thirty-seventh Conference on Neural Information Processing Systems                                                             </p> <p>[May, 2023] SPRING: Studying the Paper and Reasoning to Play Games, Yue Wu et al., arXiv                                                                                                                                                        </p> <p>[March, 2023] DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents, Varun Nair et al., arXiv                                                                                                                   </p>"},{"location":"#finetuning","title":"Finetuning","text":"<p>[October, 2023] Understanding HTML with Large Language Models, Izzeddin Gur et al., arXiv                                                                                                                                                      [ May, 2023] Instruction-Finetuned Foundation Models for Multimodal Web Navigation, Hiroki Furuta et al., ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models                                          </p> <p>[October, 2023] ReAct: Synergizing Reasoning and Acting in Language Models, Shunyu Yao et al., arXiv                                                                                                                                            </p> <p>[January, 2024] A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis, Izzeddin Gur et al., The Twelfth International Conference on Learning Representations                                         </p> <p>[November, 2023] From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces, Peter Shaw et al., Thirty-seventh Conference on Neural Information Processing Systems                       </p> <p>[January, 2024] GPT-4V(ision) is a Generalist Web Agent, if Grounded, Boyuan Zheng et al., arXiv                                                                                                                                                </p> <p>[February, 2024] Dual-View Visual Contextualization for Web Navigation, Jihyung Kil et al., arXiv           </p>"},{"location":"#reinforcement-learning","title":"Reinforcement learning","text":""},{"location":"#evaluating-social-agents","title":"Evaluating social agents","text":""},{"location":"#evaluating-text-social-agents","title":"Evaluating text social agents","text":"<p>[October, 2024] SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents, Xuhui Zhou et al., ICLR</p> <p>[October, 2023] CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents, Qinlin Zhao et al., arXiv</p> <p>[March, 2024] How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments, Jen-tse Huang et al., arXiv </p> <p>[August, 2023] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate, Chi-Min Chan et al., arXiv</p> <p>[February, 2024] Automatic Evaluation for Mental Health Counseling using LLMs, Anqi Li et al., arXiv </p> <p>[February, 2024] How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis, Federico Bianchi et al., arXiv</p> <p>[May, 2023] PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits, Hang Jiang et al., NAACL Findings  </p> <p>[February, 2024] Can Large Language Model Agents Simulate Human Trust Behaviors?, Chengxing Xie et al., ArXiv</p> <p>[January, 2024] LLM Harmony: Multi-Agent Communication for Problem Solving, Sumedh Rasal et al., ArXiv</p> <p>[November, 2021] A Comprehensive Assessment of Dialog Evaluation Metrics, Yeh et al., The First Workshop on Evaluations and Assessments of Neural Conversation Systems</p> <p>[July, 2020] {C}onvo{K}it: A Toolkit for the Analysis of Conversations, Chang et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p>"},{"location":"#evaluating-embodied-social-agents","title":"Evaluating embodied social agents","text":"<p>[March, 2024] Embodied LLM Agents Learn to Cooperate in Organized Teams, Xudong Guo et al., arXiv</p>"},{"location":"#evaluating-virtual-social-agents","title":"Evaluating virtual social agents","text":""},{"location":"#evaluating-robotics-in-social-contexts","title":"Evaluating robotics in social contexts","text":"<p>[March, 2024] Embodied LLM Agents Learn to Cooperate in Organized Teams, Xudong Guo et al., arXiv                                                                                                                                               | [March, 2024] HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation, Carmelo Sferrazza et al., arXiv                                                                                                            [January, 2003] Theory and evaluation of human robot interactions, J. Scholtz et al., 36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the                                                      [March, 2006] Common metrics for human-robot interaction, Aaron Steinfeld et al., Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction                                                                         [July, 2020] Safety bounds in human robot interaction: A survey, Angeliki Zacharaki et al., Safety science                                                                                                   [October, 2011] A meta-analysis of factors affecting trust in human-robot interaction, Peter A Hancock et al., Human factors                                                                                           [November, 2009] Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots, Christoph Bartneck et al.,  [December, 2015] RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots, Luca Iocchi et al., Artificial Intelligence                                                   [December, 2020] Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition, Y. Mizuchi et al., Advanced Robotics  </p>"},{"location":"#interactions-with-humans","title":"Interactions with humans","text":""},{"location":"#human-chatbot-interaction","title":"Human-Chatbot Interaction","text":""},{"location":"#human-embodied-agent-interaction","title":"Human-Embodied Agent Interaction","text":""},{"location":"#human-robot-interaction","title":"Human Robot Interaction","text":""},{"location":"#human-human-interaction","title":"Human-Human Interaction","text":""},{"location":"#challenges","title":"Challenges","text":""},{"location":"#theory-of-mind","title":"Theory of Mind","text":""},{"location":"#social-learning","title":"Social Learning","text":""},{"location":"#simultaneous-interaction","title":"Simultaneous Interaction","text":""},{"location":"#applications","title":"Applications","text":""},{"location":"#health","title":"Health","text":""},{"location":"#policy","title":"Policy","text":"<p>[August, 2022] Social Simulacra: Creating Populated Prototypes for Social Computing Systems, Joon Sung Park et al., Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology</p> <p>[November, 2024] Do LLMs exhibit human-like response biases? A case study in survey design, Lindia Tjuatja et al., arXiv</p> <p>[February, 2024] Large language models cannot replace human participants because they cannot portray identity groups, Angelina Wang et al., arXiv</p> <p>[February, 2024] Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation, Xinyi Mou et al., arXiv</p> <p>[March, 2024] From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News, Yuhan Liu et al., arXiv                </p>"},{"location":"#education","title":"Education","text":""},{"location":"#concerns","title":"Concerns","text":""},{"location":"#risks","title":"Risks","text":""},{"location":"#safety","title":"Safety","text":""},{"location":"contribution/","title":"Contribution","text":"<p>Hi everyone! Thanks for the help!! Your expertise is invaluable to the community \ud83d\udca1. Here are some steps to contribute to the repository:</p>"},{"location":"contribution/#steps","title":"Steps","text":"<ol> <li>Fork the repository.</li> <li>Add each paper to the <code>main.bib</code> file, under the section you are working on. You could pick one section that fits the paper the most. This file will sync with the Overleaf project <code>main.bib</code> file after your PR is merged. Don't add the papers that are already in the <code>main.bib</code>.</li> <li>Add four new fields for each paper you added: <code>environments</code>, <code>agents</code>, <code>evaluation</code>, and <code>other</code>. The acceptable tags for these four fields are in taxonomy.</li> <li> <p>Update the <code>./docs/paper_table.md</code> file:</p> <ul> <li>Run <code>python bibtex_to_table.py</code> to update the <code>./docs/paper_table.md</code> file.</li> <li>Double-check the output Markdown file and ensure the table is updated correctly.</li> </ul> </li> <li> <p>Update the <code>./docs/README.md</code> file with the paper entry:</p> <ul> <li>Copy and paste the content from the <code>helper</code> column of the <code>./docs/helper.md</code> file to the corresponding section(s) in the <code>./docs/README.md</code> file.</li> <li>Note: If the paper fits multiple sections, you can paste the entry into multiple sections in the <code>./docs/README.md</code> file.</li> </ul> </li> <li> <p>Create a Pull Request:</p> <ul> <li>Once you've completed the above steps, create a pull request to the main repository.</li> <li>Congratulations! \ud83c\udf89</li> </ul> </li> </ol>"},{"location":"contribution/#notes","title":"Notes","text":"<ul> <li>If you have any questions, feel free to ask in the Slack channel or create an issue in the repository.</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>Social Agent Examples:</p> Examples Social agent Socially intelligent agent Agent outputing only yes or no \u2714, if the yes or no is somewhat meaningful \u2714, if the yes or no is interpretable by a certain group of people. But the communication bandwidth is quite limited, so its social intelligence level could be low. Agent outputting only yes \u274c, the agent could not perceive environment and act accordingly \u274c StarCraft Agents \u2714, they interact \u274c, humans cannot understand their internal signals Agents speak an artificial code language that only few people understand \u2714, they interact \u2714, they interact and communicate in a human-interpretable way Trisolarans \u2714, they interact \u274c, their way of interaction is different from how humans communicate. They are essentially mind readers, and they don't need theory of mind A newspaper, or a bot that only responds you with today's weather in Pittsburgh \u274c, it doesn't interact \u274c A Webareana agent \u274c, it only interacts with the browser environment \u274c A tree \u274c, it doesn't interact \u274c A lightbulb with motion sensor that turns on when you walk by ? ? Self-driving cars on the real road \u2714, they interact ?"},{"location":"helper/","title":"Helper","text":"<p>[July, 2023] Communicative Agents for Software Development, Chen Qian et al., arXiv</p> <p>[March, 2020] The Hanabi challenge: A new frontier for AI research, Nolan Bard et al., Artificial Intelligence</p> <p>[October, 2018] Decoupling Strategy and Generation in Negotiation Dialogues, He et al., Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</p> <p>[September, 2017] Deal or No Deal? End-to-End Learning of Negotiation Dialogues, Lewis et al., Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</p> <p>[July, 2019] Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good, Wang et al., Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</p> <p>[July, 2020] It Takes Two to Lie: One to Lie, and One to Listen, Peskov et al., Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</p> <p>[August, 2019] {OpenSpiel}: A Framework for Reinforcement Learning in Games, Marc Lanctot et al., CoRR</p> <p>[July, 2019] RLCard: A Toolkit for Reinforcement Learning in Card Games, Daochen Zha et al., arXiv preprint arXiv:1910.04376</p> <p>[November, 2022] Human-level play in the game of Diplomacy by combining language models with strategic reasoning, Meta Fundamental AI Research Diplomacy Team (FAIR)\u2020 et al., Science</p> <p>[March, 2023] Fast Multi-Agent Gridworld Environments for Gymnasium, Ini Oguntola et al., GitHub</p> <p>[December, 2022] Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence, Callison-Burch et al., Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</p> <p>[July, 2023] {I} Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons, Zhou et al., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</p> <p>[July, 2023] {FIREBALL}: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information, Zhu et al., Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</p> <p>[August, 2023] {CALYPSO}: {LLMs} as Dungeon Masters' Assistants, Andrew Zhu et al., The 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE 2023)</p> <p>[October, 2023] CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents, Qinlin Zhao et al., arXiv</p> <p>[December, 2023] RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments, Haoyu Xiong et al., Proceedings of The 6th Conference on Robot Learning</p> <p>[August, 2022] Do As I Can and Not As I Say: Grounding Language in Robotic Affordances, Michael Ahn et al., arXiv preprint arXiv:2204.01691</p> <p>[June, 2022] Inner Monologue: Embodied Reasoning through Planning with Language Models, Wenlong Huang et al., arXiv preprint arXiv:2207.05608</p> <p>[June, 2023] One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments, Yufei Wang et al., Robotics: Science and Systems (RSS)</p> <p>[August, 2023] Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration, Chen Wang et al., arXiv</p> <p>[March, 2024] Yell At Your Robot: Improving On-the-Fly from Language Corrections, Lucy Xiaoyang Shi et al., arXiv</p> <p>[April, 2016] Human--robot interaction: status and challenges, Thomas B Sheridan et al., Human factors</p> <p>[June, 2021] A taxonomy to structure and analyze human--robot interaction, Linda Onnasch et al., International Journal of Social Robotics</p> <p>[July, 2023] Robotic vision for human-robot interaction and collaboration: A survey and systematic review, Nicole Robinson et al., ACM Transactions on Human-Robot Interaction</p> <p>[October, 2022] A survey of multi-agent Human--Robot Interaction systems, Abhinav Dahiya et al., Robotics and Autonomous Systems</p> <p>[March, 2023] Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective, Jacqueline Urakami et al., J. Hum.-Robot Interact.</p> <p>[April, 2023] 15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction, Katie Winkle et al., J. Hum.-Robot Interact.</p> <p>[May, 2023] Voyager: An Open-Ended Embodied Agent with Large Language Models, Guanzhi Wang et al., arXiv</p> <p>[March, 2023] Language Models can Solve Computer Tasks, Geunwoo Kim et al., arXiv</p> <p>[September, 2024] LASER: LLM Agent with State-Space Exploration for Web Navigation, Kaixin Ma et al., arXiv</p> <p>[May, 2023] Hierarchical Prompting Assists Large Language Model on Web Navigation, Abishek Sridhar et al., arXiv</p> <p>[January, 2024] Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control, Longtao Zheng et al., The Twelfth International Conference on Learning Representations</p> <p>[November, 2023] AdaPlanner: Adaptive Planning from Feedback with Language Models, Haotian Sun et al., Thirty-seventh Conference on Neural Information Processing Systems</p> <p>[May, 2023] SPRING: Studying the Paper and Reasoning to Play Games, Yue Wu et al., arXiv</p> <p>[March, 2023] DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents, Varun Nair et al., arXiv</p> <p>[October, 2023] Understanding HTML with Large Language Models, Izzeddin Gur et al., arXiv</p> <p>[May, 2023] Instruction-Finetuned Foundation Models for Multimodal Web Navigation, Hiroki Furuta et al., ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models</p> <p>[October, 2023] ReAct: Synergizing Reasoning and Acting in Language Models, Shunyu Yao et al., arXiv</p> <p>[January, 2024] A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis, Izzeddin Gur et al., The Twelfth International Conference on Learning Representations</p> <p>[November, 2023] From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces, Peter Shaw et al., Thirty-seventh Conference on Neural Information Processing Systems</p> <p>[January, 2024] GPT-4V(ision) is a Generalist Web Agent, if Grounded, Boyuan Zheng et al., arXiv</p> <p>[February, 2024] Dual-View Visual Contextualization for Web Navigation, Jihyung Kil et al., arXiv</p> <p>[October, 2024] SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents, Xuhui Zhou et al., ICLR</p> <p>[March, 2024] How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments, Jen-tse Huang et al., arXiv</p> <p>[August, 2023] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate, Chi-Min Chan et al., arXiv</p> <p>[February, 2024] Automatic Evaluation for Mental Health Counseling using LLMs, Anqi Li et al., arXiv</p> <p>[February, 2024] How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis, Federico Bianchi et al., arXiv</p> <p>[May, 2023] PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits, Hang Jiang et al., NAACL Findings</p> <p>[February, 2024] Can Large Language Model Agents Simulate Human Trust Behaviors?, Chengxing Xie et al., ArXiv</p> <p>[January, 2024] LLM Harmony: Multi-Agent Communication for Problem Solving, Sumedh Rasal et al., ArXiv</p> <p>[November, 2021] A Comprehensive Assessment of Dialog Evaluation Metrics, Yeh et al., The First Workshop on Evaluations and Assessments of Neural Conversation Systems</p> <p>[July, 2020] {C}onvo{K}it: A Toolkit for the Analysis of Conversations, Chang et al., Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</p> <p>[March, 2024] Embodied LLM Agents Learn to Cooperate in Organized Teams, Xudong Guo et al., arXiv</p> <p>[March, 2024] HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation, Carmelo Sferrazza et al., arXiv</p> <p>[January, 2003] Theory and evaluation of human robot interactions, J. Scholtz et al., 36th Annual Hawaii International Conference on System Sciences, 2003. Proceedings of the</p> <p>[March, 2006] Common metrics for human-robot interaction, Aaron Steinfeld et al., Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction</p> <p>[July, 2020] Safety bounds in human robot interaction: A survey, Angeliki Zacharaki et al., Safety science</p> <p>[October, 2011] A meta-analysis of factors affecting trust in human-robot interaction, Peter A Hancock et al., Human factors</p> <p>[November, 2009] Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots, Christoph Bartneck et al., International journal of social robotics</p> <p>[December, 2015] RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots, Luca Iocchi et al., Artificial Intelligence</p> <p>[December, 2020] Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition, Y. Mizuchi et al., Advanced Robotics</p> <p>[August, 2022] Social Simulacra: Creating Populated Prototypes for Social Computing Systems, Joon Sung Park et al., Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology</p> <p>[November, 2024] Do LLMs exhibit human-like response biases? A case study in survey design, Lindia Tjuatja et al., arXiv</p> <p>[February, 2024] Large language models cannot replace human participants because they cannot portray identity groups, Angelina Wang et al., arXiv</p> <p>[February, 2024] Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation, Xinyi Mou et al., arXiv</p> <p>[March, 2024] From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News, Yuhan Liu et al., arXiv</p>"},{"location":"paper_table/","title":"Paper table","text":"Title Date environments agents evaluation other Communicative Agents for Software Development July, 2023 collaboration, embodied prompting_and_in_context_learning, more_than_three_agents rule_based n/a The Hanabi challenge: A new frontier for AI research March, 2020 collaboration, text more_than_three_agents rule_based n/a Decoupling Strategy and Generation in Negotiation Dialogues October, 2018 text, mixed_objectives finetuning, reinforcement_learning, two_agents, agents_with_memory human n/a Deal or No Deal? End-to-End Learning of Negotiation Dialogues September, 2017 text, mixed_objectives reinforcement_learning, two_agents, agents_with_memory rule_based human_agent Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good July, 2019 text, mixed_objectives two_agents, finetuning human, rule_based human_agent It Takes Two to Lie: One to Lie, and One to Listen July, 2020 text, mixed_objectives more_than_three_agents model_based human_agent {OpenSpiel}: A Framework for Reinforcement Learning in Games August, 2019 collaboration, competition, mixed_objectives, text two_agents, more_than_three_agents, reinforcement_learning rule_based n/a RLCard: A Toolkit for Reinforcement Learning in Card Games July, 2019 collaboration, competition, mixed_objectives, text two_agents, more_than_three_agents, reinforcement_learning rule_based n/a Human-level play in the game of Diplomacy by combining language models with strategic reasoning November, 2022 competition, text more_than_three_agents, reinforcement_learning, finetuning rule_based human_agent Fast Multi-Agent Gridworld Environments for Gymnasium March, 2023 collaboration, competition, text two_agents, more_than_three_agents, reinforcement_learning rule_based n/a Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence December, 2022 text, implicit_objectives more_than_three_agents, pretraining, finetuning human, rule_based human_agent {I} Cast Detect Thoughts: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons July, 2023 text, implicit_objectives more_than_three_agents, reinforcement_learning human, rule_based human_agent {FIREBALL}: A Dataset of Dungeons and Dragons Actual-Play with Structured Game State Information July, 2023 text, implicit_objectives more_than_three_agents, finetuning human, rule_based human_agent {CALYPSO}: {LLMs} as Dungeon Masters' Assistants August, 2023 text, implicit_objectives more_than_three_agents, finetuning human human_agent CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents October, 2023 competition, text prompting_and_in_context_learning, two_agents rule_based n/a RoboTube: Learning Household Manipulation from Human Videos with Simulated Twin Environments December, 2023 implicit_objectives, robotics reinforcement_learning, agents_with_memory human, rule_based simulated_humans Do As I Can and Not As I Say: Grounding Language in Robotic Affordances August, 2022 mixed_objectives, implicit_objectives, robotics finetuning, reinforcement_learning, agents_with_memory human, rule_based, model_based simulated_humans Inner Monologue: Embodied Reasoning through Planning with Language Models June, 2022 mixed_objectives, implicit_objectives, robotics finetuning, reinforcement_learning, agents_with_memory human, rule_based, model_based simulated_humans One Policy to Dress Them All: Learning to Dress People with Diverse Poses and Garments June, 2023 robotics reinforcement_learning human, rule_based human_agent Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration August, 2023 collaboration, mixed_objectives, robotics two_agents, reinforcement_learning human human_agent, simulated_humans Yell At Your Robot: Improving On-the-Fly from Language Corrections March, 2024 collaboration, mixed_objectives, robotics two_agents, finetuning, reinforcement_learning, agents_with_memory human human_agent Human--robot interaction: status and challenges April, 2016 collaboration, mixed_objectives, robotics two_agents, finetuning, reinforcement_learning human human_agent A taxonomy to structure and analyze human--robot interaction June, 2021 collaboration, mixed_objectives, robotics two_agents human human_agent Robotic vision for human-robot interaction and collaboration: A survey and systematic review July, 2023 collaboration, mixed_objectives, implicit_objectives, robotics two_agents, agent_teams, agents_with_personas human, rule_based human_agent, simulated_humans A survey of multi-agent Human--Robot Interaction systems October, 2022 collaboration, mixed_objectives, robotics two_agents, more_than_three_agents, agent_teams human human_agent Nonverbal Cues in Human Robot Interaction: A Communication Studies Perspective March, 2023 collaboration, mixed_objectives, implicit_objectives, robotics two_agents human human_agent 15 Years of (Who)man Robot Interaction: Reviewing the H in Human-Robot Interaction April, 2023 robotics two_agents human human_agent Voyager: An Open-Ended Embodied Agent with Large Language Models May, 2023 mixed_objectives, implicit_objectives, embodied prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans Language Models can Solve Computer Tasks March, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning rule_based simulated_humans LASER: LLM Agent with State-Space Exploration for Web Navigation September, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans Hierarchical Prompting Assists Large Language Model on Web Navigation May, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control January, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans AdaPlanner: Adaptive Planning from Feedback with Language Models November, 2023 mixed_objectives, implicit_objectives, text prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans SPRING: Studying the Paper and Reasoning to Play Games May, 2023 mixed_objectives, implicit_objectives, text prompting_and_in_context_learning, agents_with_memory rule_based simulated_humans DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents March, 2023 collaboration, mixed_objectives, implicit_objectives, text prompting_and_in_context_learning, agent_teams, agents_with_memory rule_based simulated_humans Understanding HTML with Large Language Models October, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning rule_based simulated_humans Instruction-Finetuned Foundation Models for Multimodal Web Navigation May, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans ReAct: Synergizing Reasoning and Acting in Language Models October, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis January, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans From Pixels to {UI} Actions: Learning to Follow Instructions via Graphical User Interfaces November, 2023 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans GPT-4V(ision) is a Generalist Web Agent, if Grounded January, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans Dual-View Visual Contextualization for Web Navigation February, 2024 mixed_objectives, implicit_objectives, virtual prompting_and_in_context_learning, finetuning, agents_with_memory rule_based simulated_humans SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents October, 2024 mixed_objectives, text prompting_and_in_context_learning, two_agents model_based, human human_agent How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments March, 2024 mixed_objectives, text prompting_and_in_context_learning, more_than_three_agents rule_based more_omniscient ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate August, 2023 collaboration, text prompting_and_in_context_learning, more_than_three_agents rule_based n/a Automatic Evaluation for Mental Health Counseling using LLMs February, 2024 collaboration, text prompting_and_in_context_learning, two_agents model_based n/a How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis February, 2024 mixed_objectives, text prompting_and_in_context_learning, two_agents rule_based more_information_asymmetrical PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits May, 2023 text prompting_and_in_context_learning human, model_based n/a Can Large Language Model Agents Simulate Human Trust Behaviors? February, 2024 text prompting_and_in_context_learning human, model_based n/a LLM Harmony: Multi-Agent Communication for Problem Solving January, 2024 text prompting_and_in_context_learning human, model_based n/a A Comprehensive Assessment of Dialog Evaluation Metrics November, 2021 text n/a human, model_based, rule_based n/a {C}onvo{K}it: A Toolkit for the Analysis of Conversations July, 2020 text n/a human, model_based, rule_based n/a Embodied LLM Agents Learn to Cooperate in Organized Teams March, 2024 collaboration, embodied prompting_and_in_context_learning, more_than_three_agents model_based, human education HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation March, 2024 collaboration, mixed_objectives, robotics reinforcement_learning human, model_based human_agent, simulated_humans Theory and evaluation of human robot interactions January, 2003 collaboration, mixed_objectives, robotics reinforcement_learning human human_agent Common metrics for human-robot interaction March, 2006 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based, model_based human_agent Safety bounds in human robot interaction: A survey July, 2020 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent A meta-analysis of factors affecting trust in human-robot interaction October, 2011 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent Measurement instruments for the anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety of robots November, 2009 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent RoboCup@ Home: Analysis and results of evolving competitions for domestic and service robots December, 2015 collaboration, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent Optimization of criterion for objective evaluation of HRI performance that approximates subjective evaluation: a case study in robot competition December, 2020 competition, mixed_objectives, robotics reinforcement_learning human, rule_based human_agent Social Simulacra: Creating Populated Prototypes for Social Computing Systems August, 2022 text, implicit_objectives more_than_three_agents human policy Do LLMs exhibit human-like response biases? A case study in survey design November, 2024 text prompting_and_in_context_learning human, model_based policy Large language models cannot replace human participants because they cannot portray identity groups February, 2024 text n/a n/a policy Unveiling the Truth and Facilitating Change: Towards Agent-based Large-scale Social Movement Simulation February, 2024 text more_than_three_agents model_based policy From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News March, 2024 text more_than_three_agents model_based policy"},{"location":"paper_table/#basic-stats","title":"Basic Stats","text":"<p>Total number of papers: 66</p>"},{"location":"paper_table/#subsections","title":"Subsections","text":"<p>environments/language: 14 environments/robotics: 12 modeling/in-context-learning: 8 modeling/finetuning: 7 evaluation/language: 10 evaluation/embodied: 1 evaluation/robotics: 8 applications/policy: 5</p>"},{"location":"taxonomy/","title":"Tags that you can add to each field","text":"<p>We ask you to add four additional fields to each bibtex entry. The format of a bibtex you should add to <code>main.bib</code> is as follows</p> <pre><code>@misc{Nobody37,\n    author = \"Nobody Jr\",\n    title = \"The last missing piece of AGI\",\n    year = \"2037\",\n    url = \"https://pdf.agi.org\",\n    environments = {mixed_objectives, implicit_objectives, robotics},\n    agents = {agent_teams, more_than_three_agents, agents_with_memory, agents_with_personas},\n    evaluation = {model_based},\n    other = {human_involvement}\n}</code></pre>"},{"location":"taxonomy/#1-environments-and-tasks","title":"1 Environments and Tasks","text":"<p>Here are acceptable tags for <code>environments</code> field: <pre><code>collaboration, competition, mixed_objectives, implicit_objectives,\ntext, virtual, embodied, robotics,\nn/a</code></pre> Please find the explanations to each of these tags below:</p>"},{"location":"taxonomy/#social-interaction-types","title":"Social interaction types","text":"<ol> <li>Collaboration (<code>collaboration</code>): The objectives are shared among agents</li> <li>Competition (<code>competition</code>): The objectives are zero-sum</li> <li>Mixed Objectives (<code>mixed_objectives</code>): Agents\u2019 have different goals, but they are not zero-sum</li> <li>Implicit Objectives (<code>implicit_objectives</code>): Goals are not expressed explicitly</li> </ol>"},{"location":"taxonomy/#domains","title":"Domains","text":"<ol> <li>Text (<code>text</code>): non-embodied environments with text-based observation spaces and action spaces, e.g. chatbots environment</li> <li>Virtual (<code>virtual</code>): non-embodied environments with multimodal observation spaces and/or actions spaces, e.g. web browser environment</li> <li>Embodied (<code>embodied</code>): environments where policies interact with the world through the observation and actions of \"bodies\" (which also implies ego-centric view). A body typically takes up space and has the ability to influence the environment, e.g. Minecraft, Habitat, AI2THOR </li> <li>Robotics (<code>robotics</code>): real physical world environment</li> </ol> <p>Embodied environments in principle include robotics environments, but here we consider only the non-real physical world ones as embodied environments. </p> <p><code>n/a</code> means there is no environment in the paper, or the environment is not covered in the above categorization. Please use <code>n/a</code> sparingly.</p>"},{"location":"taxonomy/#2-agents-and-modeling","title":"2 Agents and Modeling","text":"<p>Here are acceptable tags for <code>agents</code> field: <pre><code>prompting_and_in_context_learning, finetuning, reinforcement_learning, pretraining,\ntwo_agents, more_than_three_agents, agent_teams,\nagents_with_memory, agents_with_personas,\nn/a</code></pre> These tags are straight-forward. Please note that we do count humans as agents here. <code>n/a</code> is similar to above. </p>"},{"location":"taxonomy/#3-evaluation","title":"3 Evaluation","text":"<p>Here are acceptable tags for <code>agents</code> field: <pre><code>qualitative, human, rule_based, model_based,\nn/a</code></pre></p> <ol> <li>Only qualitative evaluation (<code>qualitative</code>): You should definitely add this tag if a work is only based on qualitative evaluation</li> <li>Human evaluation (<code>human</code>): Quantitative evaluation based on human judgment</li> <li>Rule-based evaluation (<code>rule_based</code>): The evaluation is based on a set of rules</li> <li>Model-based evaluation (<code>model_based</code>): Using machine learning model to judge</li> </ol>"},{"location":"taxonomy/#4-other","title":"4 Other","text":"<p>Here are acceptable tags for <code>other</code> field: <pre><code>human_agent, simulated_humans, \nhealth, education, policy,\nfully omniscient, more omniscient, more information asymmetrical\nn/a</code></pre></p>"},{"location":"taxonomy/#human-involvement","title":"Human involvement","text":"<p><code>human_agent</code> means at least one of the agent is a human. <code>simulated_humans</code> means the agents are simulated humans.</p>"},{"location":"taxonomy/#application-domains","title":"Application domains","text":"<p><code>health</code> and <code>education</code> are self-explanatory. <code>policy</code> means the simulation is related to policy-making.</p>"},{"location":"taxonomy/#information-asymmetry-levels","title":"Information asymmetry levels","text":"<p><code>fully_omniscient</code> means all agents have full information about the environment and other agents. <code>more_omniscient</code> means agents have only one or two sources of information that other agents do not have (in the prompts for LLM-powered agents). This includes but not limited to roles, output format, occupation, partial overview of the environment, etc. <code>more_information_asymmetrical</code> means agents have various of different information sources that other agents do not have.</p> <p>Here you can use <code>n/a</code> if none of the above tags fits the paper.</p>"}]}